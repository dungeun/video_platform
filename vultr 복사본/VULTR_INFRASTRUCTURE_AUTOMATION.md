# ğŸš€ Vultr ì¸í”„ë¼ ìë™í™” ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [Vultr API í‚¤ ìƒì„±](#1-vultr-api-í‚¤-ìƒì„±)
2. [Vultr CLI ì„¤ì •](#2-vultr-cli-ì„¤ì •)
3. [Terraform ì¸í”„ë¼ ì½”ë“œí™”](#3-terraform-ì¸í”„ë¼-ì½”ë“œí™”)
4. [ìë™í™” ìŠ¤í¬ë¦½íŠ¸](#4-ìë™í™”-ìŠ¤í¬ë¦½íŠ¸)
5. [CI/CD í†µí•©](#5-cicd-í†µí•©)

---

## 1. Vultr API í‚¤ ìƒì„±

### ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ ìƒì„±
```
1. https://my.vultr.com/settings/#settingsapi ì ‘ì†
2. "Personal Access Token" ì„¹ì…˜
3. "Generate New Token" í´ë¦­
4. ê¶Œí•œ ì„¤ì •:
   - Full Access (ëª¨ë“  ê¶Œí•œ) ë˜ëŠ”
   - Custom (í•„ìš”í•œ ê¶Œí•œë§Œ):
     âœ… Instances: Read/Write
     âœ… Block Storage: Read/Write
     âœ… Snapshots: Read/Write
     âœ… Firewall: Read/Write
     âœ… DNS: Read/Write
5. API í‚¤ ë³µì‚¬ (âš ï¸ í•œ ë²ˆë§Œ í‘œì‹œë¨!)
```

### API í‚¤ ì•ˆì „í•œ ì €ì¥
```bash
# í™˜ê²½ ë³€ìˆ˜ë¡œ ì €ì¥ (ì„ì‹œ)
export VULTR_API_KEY="your-api-key-here"

# ì˜êµ¬ ì €ì¥ (.bashrc)
echo 'export VULTR_API_KEY="your-api-key-here"' >> ~/.bashrc
source ~/.bashrc

# ë˜ëŠ” .env íŒŒì¼
echo "VULTR_API_KEY=your-api-key-here" > .env
chmod 600 .env
```

---

## 2. Vultr CLI ì„¤ì •

### ì„¤ì¹˜

#### macOS
```bash
brew install vultr/vultr-cli/vultr-cli
```

#### Linux (ì„œë²„ì— ì„¤ì¹˜)
```bash
# ìµœì‹  ë²„ì „ ë‹¤ìš´ë¡œë“œ
curl -L https://github.com/vultr/vultr-cli/releases/latest/download/vultr-cli_Linux_x86_64.tar.gz | tar xz
sudo mv vultr-cli /usr/local/bin/
chmod +x /usr/local/bin/vultr-cli

# ë²„ì „ í™•ì¸
vultr-cli version
```

#### Docker ë°©ì‹
```bash
# Docker ì´ë¯¸ì§€ë¡œ ì‹¤í–‰
docker run --rm -e VULTR_API_KEY=$VULTR_API_KEY vultr/vultr-cli:latest instance list
```

### CLI ì„¤ì •
```bash
# ëŒ€í™”í˜• ì„¤ì •
vultr-cli configure

# ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
export VULTR_API_KEY="your-api-key-here"

# ì„¤ì • í™•ì¸
vultr-cli account
```

### ê¸°ë³¸ ëª…ë ¹ì–´
```bash
# ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
vultr-cli instance list                           # ì„œë²„ ëª©ë¡
vultr-cli instance get <instance-id>              # ìƒì„¸ ì •ë³´
vultr-cli instance create --region sgp --plan vc2-2c-16gb --os 1743  # ìƒì„±
vultr-cli instance restart <instance-id>          # ì¬ì‹œì‘
vultr-cli instance delete <instance-id>           # ì‚­ì œ

# Block Storage
vultr-cli block-storage list                      # ëª©ë¡
vultr-cli block-storage create --region sgp --size 100 --label backup
vultr-cli block-storage attach <storage-id> --instance <instance-id>
vultr-cli block-storage detach <storage-id>
vultr-cli block-storage delete <storage-id>

# ìŠ¤ëƒ…ìƒ·
vultr-cli snapshot list                           # ëª©ë¡
vultr-cli snapshot create --instance-id <id> --description "backup"
vultr-cli snapshot delete <snapshot-id>

# ë°©í™”ë²½
vultr-cli firewall group list                     # ê·¸ë£¹ ëª©ë¡
vultr-cli firewall rule list <group-id>           # ê·œì¹™ ëª©ë¡
vultr-cli firewall rule create --id <group-id> --protocol tcp --port 443
```

---

## 3. Terraform ì¸í”„ë¼ ì½”ë“œí™”

### Terraform ì„¤ì¹˜

#### macOS
```bash
brew install terraform
```

#### Linux
```bash
# HashiCorp ê³µì‹ ì €ì¥ì†Œ ì¶”ê°€
curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
sudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
sudo apt update && sudo apt install terraform
```

### í”„ë¡œì íŠ¸ êµ¬ì¡°
```
infrastructure/
â”œâ”€â”€ terraform.tfvars      # ë³€ìˆ˜ ê°’ (gitignore)
â”œâ”€â”€ variables.tf          # ë³€ìˆ˜ ì •ì˜
â”œâ”€â”€ providers.tf          # Provider ì„¤ì •
â”œâ”€â”€ main.tf              # ë©”ì¸ ë¦¬ì†ŒìŠ¤
â”œâ”€â”€ outputs.tf           # ì¶œë ¥ ê°’
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ coolify/         # Coolify ëª¨ë“ˆ
â”‚   â”œâ”€â”€ monitoring/      # ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆ
â”‚   â””â”€â”€ backup/          # ë°±ì—… ëª¨ë“ˆ
â””â”€â”€ environments/
    â”œâ”€â”€ production/      # í”„ë¡œë•ì…˜ í™˜ê²½
    â””â”€â”€ staging/         # ìŠ¤í…Œì´ì§• í™˜ê²½
```

### ê¸°ë³¸ ì„¤ì • íŒŒì¼

#### `providers.tf`
```hcl
terraform {
  required_version = ">= 1.0"
  
  required_providers {
    vultr = {
      source  = "vultr/vultr"
      version = "~> 2.17"
    }
  }
  
  # ìƒíƒœ íŒŒì¼ ì›ê²© ì €ì¥ (ì„ íƒì‚¬í•­)
  backend "s3" {
    bucket = "terraform-state-bucket"
    key    = "vultr/terraform.tfstate"
    region = "ap-northeast-2"
  }
}

provider "vultr" {
  api_key = var.vultr_api_key
  rate_limit = 100  # API í˜¸ì¶œ ì œí•œ
  retry_limit = 3   # ì¬ì‹œë„ íšŸìˆ˜
}
```

#### `variables.tf`
```hcl
variable "vultr_api_key" {
  description = "Vultr API Key"
  type        = string
  sensitive   = true
}

variable "region" {
  description = "Vultr Region"
  type        = string
  default     = "sgp"  # Singapore
}

variable "environment" {
  description = "Environment name"
  type        = string
  default     = "production"
}

variable "instance_plan" {
  description = "Instance plan"
  type        = string
  default     = "vc2-2c-16gb"  # 2 vCPU, 16GB RAM
}

variable "os_id" {
  description = "Operating System ID"
  type        = number
  default     = 1743  # Ubuntu 22.04 LTS x64
}

variable "backup_storage_size" {
  description = "Block storage size in GB"
  type        = number
  default     = 100
}

variable "enable_monitoring" {
  description = "Enable monitoring"
  type        = bool
  default     = true
}

variable "enable_backups" {
  description = "Enable automatic backups"
  type        = bool
  default     = true
}
```

#### `main.tf`
```hcl
# SSH í‚¤ ìƒì„±
resource "vultr_ssh_key" "main" {
  name    = "${var.environment}-ssh-key"
  ssh_key = file("~/.ssh/id_rsa.pub")
}

# ë°©í™”ë²½ ê·¸ë£¹
resource "vultr_firewall_group" "main" {
  description = "${var.environment}-firewall"
}

# ë°©í™”ë²½ ê·œì¹™
resource "vultr_firewall_rule" "ssh" {
  firewall_group_id = vultr_firewall_group.main.id
  protocol          = "tcp"
  ip_type          = "v4"
  subnet           = "0.0.0.0"
  subnet_size      = 0
  port             = "22"
  notes            = "SSH"
}

resource "vultr_firewall_rule" "http" {
  firewall_group_id = vultr_firewall_group.main.id
  protocol          = "tcp"
  ip_type          = "v4"
  subnet           = "0.0.0.0"
  subnet_size      = 0
  port             = "80"
  notes            = "HTTP"
}

resource "vultr_firewall_rule" "https" {
  firewall_group_id = vultr_firewall_group.main.id
  protocol          = "tcp"
  ip_type          = "v4"
  subnet           = "0.0.0.0"
  subnet_size      = 0
  port             = "443"
  notes            = "HTTPS"
}

resource "vultr_firewall_rule" "coolify" {
  firewall_group_id = vultr_firewall_group.main.id
  protocol          = "tcp"
  ip_type          = "v4"
  subnet           = "0.0.0.0"
  subnet_size      = 0
  port             = "8000"
  notes            = "Coolify Panel"
}

# ë©”ì¸ ì¸ìŠ¤í„´ìŠ¤
resource "vultr_instance" "main" {
  label             = "${var.environment}-coolify-server"
  plan              = var.instance_plan
  region            = var.region
  os_id             = var.os_id
  enable_ipv6       = true
  backups           = var.enable_backups ? "enabled" : "disabled"
  backups_schedule {
    type = "daily"
    hour = 3
  }
  ddos_protection   = false
  activation_email  = false
  ssh_key_ids       = [vultr_ssh_key.main.id]
  firewall_group_id = vultr_firewall_group.main.id
  
  # ì‚¬ìš©ì ë°ì´í„° (ì´ˆê¸° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸)
  user_data = base64encode(templatefile("${path.module}/scripts/init.sh", {
    environment = var.environment
  }))
  
  tags = {
    Environment = var.environment
    Managed     = "Terraform"
    Purpose     = "Coolify"
  }
}

# Block Storage
resource "vultr_block_storage" "backup" {
  count = var.enable_backups ? 1 : 0
  
  size_gb  = var.backup_storage_size
  region   = var.region
  label    = "${var.environment}-backup-storage"
  
  # ìë™ìœ¼ë¡œ ì¸ìŠ¤í„´ìŠ¤ì— ì—°ê²°
  attached_to_instance = vultr_instance.main.id
}

# ìŠ¤ëƒ…ìƒ· (ìˆ˜ë™ íŠ¸ë¦¬ê±°)
resource "null_resource" "snapshot" {
  count = var.enable_backups ? 1 : 0
  
  provisioner "local-exec" {
    command = <<-EOT
      vultr-cli snapshot create \
        --instance-id ${vultr_instance.main.id} \
        --description "${var.environment}-snapshot-${timestamp()}"
    EOT
  }
  
  triggers = {
    # ë§¤ì¼ ì‹¤í–‰ë˜ë„ë¡ íŠ¸ë¦¬ê±°
    daily = timestamp()
  }
}

# Reserved IP (ê³ ì • IP)
resource "vultr_reserved_ip" "main" {
  region   = var.region
  ip_type  = "v4"
  label    = "${var.environment}-reserved-ip"
  instance = vultr_instance.main.id
}

# DNS ë ˆì½”ë“œ (ì„ íƒì‚¬í•­)
resource "vultr_dns_domain" "main" {
  domain = "example.com"
  ip     = vultr_reserved_ip.main.subnet
}

resource "vultr_dns_record" "a" {
  domain = vultr_dns_domain.main.id
  name   = "@"
  type   = "A"
  data   = vultr_reserved_ip.main.subnet
  ttl    = 300
}

resource "vultr_dns_record" "www" {
  domain = vultr_dns_domain.main.id
  name   = "www"
  type   = "CNAME"
  data   = vultr_dns_domain.main.domain
  ttl    = 300
}
```

#### `outputs.tf`
```hcl
output "instance_id" {
  description = "Instance ID"
  value       = vultr_instance.main.id
}

output "instance_ip" {
  description = "Instance IP address"
  value       = vultr_instance.main.main_ip
}

output "reserved_ip" {
  description = "Reserved IP address"
  value       = vultr_reserved_ip.main.subnet
}

output "ssh_command" {
  description = "SSH connection command"
  value       = "ssh root@${vultr_reserved_ip.main.subnet}"
}

output "coolify_url" {
  description = "Coolify panel URL"
  value       = "https://${vultr_reserved_ip.main.subnet}:8000"
}

output "block_storage_id" {
  description = "Block storage ID"
  value       = var.enable_backups ? vultr_block_storage.backup[0].id : null
}
```

#### `terraform.tfvars` (gitignoreì— ì¶”ê°€)
```hcl
vultr_api_key = "your-actual-api-key-here"
region         = "sgp"
environment    = "production"
instance_plan  = "vc2-2c-16gb"
```

### Terraform ì‹¤í–‰

#### ì´ˆê¸°í™”
```bash
cd infrastructure
terraform init
```

#### ê³„íš í™•ì¸
```bash
terraform plan
```

#### ì ìš©
```bash
terraform apply

# ìë™ ìŠ¹ì¸
terraform apply -auto-approve
```

#### í˜„ì¬ ì¸í”„ë¼ ê°€ì ¸ì˜¤ê¸° (Import)
```bash
# ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
terraform import vultr_instance.main <instance-id>

# ê¸°ì¡´ Block Storage ê°€ì ¸ì˜¤ê¸°
terraform import vultr_block_storage.backup[0] <storage-id>
```

#### ìƒíƒœ í™•ì¸
```bash
terraform show
terraform state list
```

#### ì‚­ì œ
```bash
terraform destroy
```

---

## 4. ìë™í™” ìŠ¤í¬ë¦½íŠ¸

### í†µí•© ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# vultr-automation.sh

set -e

# ìƒ‰ìƒ ì½”ë“œ
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# ì„¤ì •
TERRAFORM_DIR="./infrastructure"
BACKUP_DIR="/mnt/blockstorage/backups"
LOG_FILE="/var/log/vultr-automation.log"

# ë¡œê¹… í•¨ìˆ˜
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# 1. ì¸í”„ë¼ ë°°í¬
deploy_infrastructure() {
    echo -e "${BLUE}=== ì¸í”„ë¼ ë°°í¬ ì‹œì‘ ===${NC}"
    
    cd $TERRAFORM_DIR
    
    # Terraform ì´ˆê¸°í™”
    if [ ! -d ".terraform" ]; then
        log "Terraform ì´ˆê¸°í™” ì¤‘..."
        terraform init
    fi
    
    # ê³„íš ìƒì„±
    log "ë°°í¬ ê³„íš ìƒì„± ì¤‘..."
    terraform plan -out=tfplan
    
    # ì‚¬ìš©ì í™•ì¸
    echo -e "${YELLOW}ìœ„ ê³„íšì„ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no)${NC}"
    read -r response
    
    if [ "$response" = "yes" ]; then
        log "ì¸í”„ë¼ ë°°í¬ ì¤‘..."
        terraform apply tfplan
        echo -e "${GREEN}âœ… ì¸í”„ë¼ ë°°í¬ ì™„ë£Œ${NC}"
    else
        echo -e "${RED}âŒ ë°°í¬ ì·¨ì†Œë¨${NC}"
        rm tfplan
        return 1
    fi
    
    cd -
}

# 2. ì„œë²„ ì´ˆê¸° ì„¤ì •
initialize_server() {
    echo -e "${BLUE}=== ì„œë²„ ì´ˆê¸° ì„¤ì • ===${NC}"
    
    # Terraform ì¶œë ¥ì—ì„œ IP ê°€ì ¸ì˜¤ê¸°
    SERVER_IP=$(cd $TERRAFORM_DIR && terraform output -raw instance_ip)
    
    log "ì„œë²„ ì ‘ì†: $SERVER_IP"
    
    # ì´ˆê¸° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    ssh root@$SERVER_IP << 'ENDSSH'
        # ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
        apt update && apt upgrade -y
        
        # í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
        apt install -y docker.io docker-compose git htop ncdu
        
        # Docker ì„¤ì •
        systemctl enable docker
        systemctl start docker
        
        # Swap ì„¤ì • (ë©”ëª¨ë¦¬ ë³´ì¡°)
        if [ ! -f /swapfile ]; then
            fallocate -l 8G /swapfile
            chmod 600 /swapfile
            mkswap /swapfile
            swapon /swapfile
            echo '/swapfile none swap sw 0 0' >> /etc/fstab
        fi
        
        # ë³´ì•ˆ ì„¤ì •
        ufw allow 22/tcp
        ufw allow 80/tcp
        ufw allow 443/tcp
        ufw allow 8000/tcp
        ufw --force enable
        
        # Coolify ì„¤ì¹˜
        if [ ! -d "/root/coolify" ]; then
            curl -fsSL https://get.coolify.io | bash
        fi
        
        echo "âœ… ì„œë²„ ì´ˆê¸° ì„¤ì • ì™„ë£Œ"
ENDSSH
    
    echo -e "${GREEN}âœ… ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ${NC}"
}

# 3. Block Storage ì„¤ì •
setup_block_storage() {
    echo -e "${BLUE}=== Block Storage ì„¤ì • ===${NC}"
    
    # Storage ID ê°€ì ¸ì˜¤ê¸°
    STORAGE_ID=$(cd $TERRAFORM_DIR && terraform output -raw block_storage_id)
    SERVER_IP=$(cd $TERRAFORM_DIR && terraform output -raw instance_ip)
    
    if [ "$STORAGE_ID" = "null" ]; then
        echo -e "${YELLOW}Block Storageê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ${NC}"
        return 1
    fi
    
    log "Block Storage ë§ˆìš´íŠ¸ ì¤‘: $STORAGE_ID"
    
    ssh root@$SERVER_IP << 'ENDSSH'
        # ë””ë°”ì´ìŠ¤ í™•ì¸
        DEVICE=$(lsblk -rno NAME,TYPE | grep disk | grep -v vda | head -1 | awk '{print $1}')
        
        if [ -n "$DEVICE" ]; then
            # í¬ë§· (ì²˜ìŒë§Œ)
            if ! blkid /dev/$DEVICE; then
                mkfs.ext4 /dev/$DEVICE
            fi
            
            # ë§ˆìš´íŠ¸
            mkdir -p /mnt/blockstorage
            mount /dev/$DEVICE /mnt/blockstorage
            
            # ìë™ ë§ˆìš´íŠ¸ ì„¤ì •
            UUID=$(blkid -s UUID -o value /dev/$DEVICE)
            if ! grep -q "$UUID" /etc/fstab; then
                echo "UUID=$UUID /mnt/blockstorage ext4 defaults,nofail 0 0" >> /etc/fstab
            fi
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            mkdir -p /mnt/blockstorage/{backups,docker-volumes,logs,snapshots}
            mkdir -p /mnt/blockstorage/backups/{daily,weekly,monthly}
            
            echo "âœ… Block Storage ë§ˆìš´íŠ¸ ì™„ë£Œ"
        else
            echo "âŒ Block Storage ë””ë°”ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"
            exit 1
        fi
ENDSSH
    
    echo -e "${GREEN}âœ… Block Storage ì„¤ì • ì™„ë£Œ${NC}"
}

# 4. ë°±ì—… ìë™í™” ì„¤ì •
setup_backups() {
    echo -e "${BLUE}=== ë°±ì—… ìë™í™” ì„¤ì • ===${NC}"
    
    SERVER_IP=$(cd $TERRAFORM_DIR && terraform output -raw instance_ip)
    
    log "ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘..."
    
    ssh root@$SERVER_IP << 'ENDSSH'
        # ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        cat > /usr/local/bin/auto-backup.sh << 'EOF'
#!/bin/bash

BACKUP_DIR="/mnt/blockstorage/backups/daily"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

# PostgreSQL ë°±ì—…
for container in $(docker ps --format '{{.Names}}' | grep postgres); do
    docker exec $container pg_dumpall -U postgres | \
    gzip > $BACKUP_DIR/postgres_${container}_${DATE}.sql.gz
done

# Docker ë³¼ë¥¨ ë°±ì—…
docker run --rm \
    -v /var/lib/docker/volumes:/source:ro \
    -v $BACKUP_DIR:/backup \
    alpine tar czf /backup/docker_volumes_${DATE}.tar.gz /source

# Coolify ì„¤ì • ë°±ì—…
tar czf $BACKUP_DIR/coolify_config_${DATE}.tar.gz \
    /root/coolify/.env \
    /root/coolify/docker-compose.yml

# ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
find $BACKUP_DIR -type f -mtime +$RETENTION_DAYS -delete

# ì£¼ê°„ ë°±ì—… (ì¼ìš”ì¼)
if [ $(date +%u) -eq 7 ]; then
    cp $BACKUP_DIR/*_${DATE}.* /mnt/blockstorage/backups/weekly/
fi

# ì›”ê°„ ë°±ì—… (1ì¼)
if [ $(date +%d) -eq 01 ]; then
    cp $BACKUP_DIR/*_${DATE}.* /mnt/blockstorage/backups/monthly/
fi

echo "[$(date)] ë°±ì—… ì™„ë£Œ" >> /var/log/backup.log
EOF
        
        chmod +x /usr/local/bin/auto-backup.sh
        
        # Cron ì„¤ì •
        (crontab -l 2>/dev/null; echo "0 3 * * * /usr/local/bin/auto-backup.sh") | crontab -
        
        echo "âœ… ë°±ì—… ìë™í™” ì„¤ì • ì™„ë£Œ"
ENDSSH
    
    echo -e "${GREEN}âœ… ë°±ì—… ì„¤ì • ì™„ë£Œ${NC}"
}

# 5. ëª¨ë‹ˆí„°ë§ ì„¤ì •
setup_monitoring() {
    echo -e "${BLUE}=== ëª¨ë‹ˆí„°ë§ ì„¤ì • ===${NC}"
    
    SERVER_IP=$(cd $TERRAFORM_DIR && terraform output -raw instance_ip)
    
    log "Netdata ì„¤ì¹˜ ì¤‘..."
    
    ssh root@$SERVER_IP << 'ENDSSH'
        # Netdata ì„¤ì¹˜
        if ! systemctl is-active --quiet netdata; then
            bash <(curl -Ss https://get.netdata.cloud/kickstart.sh) --dont-wait
        fi
        
        # Uptime Kuma ì„¤ì¹˜
        if [ ! -d "/root/uptime-kuma" ]; then
            mkdir -p /root/uptime-kuma
            cat > /root/uptime-kuma/docker-compose.yml << 'EOF'
version: '3.8'

services:
  uptime-kuma:
    image: louislam/uptime-kuma:1
    container_name: uptime-kuma
    volumes:
      - ./data:/app/data
    ports:
      - "3001:3001"
    restart: always
EOF
            cd /root/uptime-kuma
            docker-compose up -d
        fi
        
        echo "âœ… ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ"
        echo "Netdata: http://$SERVER_IP:19999"
        echo "Uptime Kuma: http://$SERVER_IP:3001"
ENDSSH
    
    echo -e "${GREEN}âœ… ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ${NC}"
}

# 6. ìƒíƒœ í™•ì¸
check_status() {
    echo -e "${BLUE}=== ì¸í”„ë¼ ìƒíƒœ í™•ì¸ ===${NC}"
    
    # Terraform ìƒíƒœ
    echo -e "${YELLOW}Terraform ë¦¬ì†ŒìŠ¤:${NC}"
    cd $TERRAFORM_DIR
    terraform state list
    
    # ì„œë²„ ìƒíƒœ
    SERVER_IP=$(terraform output -raw instance_ip)
    echo -e "\n${YELLOW}ì„œë²„ ìƒíƒœ:${NC}"
    vultr-cli instance get $(terraform output -raw instance_id) | \
        grep -E "LABEL|STATUS|MAIN_IP|VCPU|RAM"
    
    # SSH ì—°ê²° í…ŒìŠ¤íŠ¸
    echo -e "\n${YELLOW}SSH ì—°ê²° í…ŒìŠ¤íŠ¸:${NC}"
    if ssh -o ConnectTimeout=5 root@$SERVER_IP "echo 'âœ… SSH ì—°ê²° ì„±ê³µ'"; then
        echo -e "${GREEN}ì„œë²„ ì ‘ì† ê°€ëŠ¥${NC}"
    else
        echo -e "${RED}ì„œë²„ ì ‘ì† ë¶ˆê°€${NC}"
    fi
    
    cd -
}

# 7. ì¬í•´ ë³µêµ¬
disaster_recovery() {
    echo -e "${RED}=== ì¬í•´ ë³µêµ¬ ëª¨ë“œ ===${NC}"
    
    echo -e "${YELLOW}ìŠ¤ëƒ…ìƒ· ëª©ë¡:${NC}"
    vultr-cli snapshot list
    
    echo "ë³µêµ¬í•  ìŠ¤ëƒ…ìƒ· IDë¥¼ ì…ë ¥í•˜ì„¸ìš”:"
    read -r SNAPSHOT_ID
    
    echo -e "${YELLOW}ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...${NC}"
    NEW_INSTANCE=$(vultr-cli instance create \
        --region sgp \
        --plan vc2-2c-16gb \
        --snapshot $SNAPSHOT_ID \
        --label "recovery-$(date +%Y%m%d)" \
        --output json | jq -r '.instance.id')
    
    echo -e "${GREEN}âœ… ë³µêµ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±: $NEW_INSTANCE${NC}"
    
    # Terraform ìƒíƒœ ì—…ë°ì´íŠ¸
    cd $TERRAFORM_DIR
    terraform import vultr_instance.main $NEW_INSTANCE
    cd -
}

# ë©”ì¸ ë©”ë‰´
show_menu() {
    echo -e "${BLUE}================================${NC}"
    echo -e "${BLUE}   Vultr ì¸í”„ë¼ ìë™í™” ë„êµ¬${NC}"
    echo -e "${BLUE}================================${NC}"
    echo "1. ì¸í”„ë¼ ë°°í¬ (Terraform)"
    echo "2. ì„œë²„ ì´ˆê¸° ì„¤ì •"
    echo "3. Block Storage ì„¤ì •"
    echo "4. ë°±ì—… ìë™í™” ì„¤ì •"
    echo "5. ëª¨ë‹ˆí„°ë§ ì„¤ì •"
    echo "6. ìƒíƒœ í™•ì¸"
    echo "7. ì¬í•´ ë³µêµ¬"
    echo "8. ì „ì²´ ì„¤ì • (1-5 ìˆœì°¨ ì‹¤í–‰)"
    echo "0. ì¢…ë£Œ"
    echo -e "${BLUE}================================${NC}"
    echo -n "ì„ íƒ: "
}

# ì „ì²´ ì„¤ì •
full_setup() {
    log "ì „ì²´ ì„¤ì • ì‹œì‘"
    deploy_infrastructure && \
    sleep 30 && \
    initialize_server && \
    setup_block_storage && \
    setup_backups && \
    setup_monitoring && \
    check_status
    log "ì „ì²´ ì„¤ì • ì™„ë£Œ"
}

# ë©”ì¸ ë£¨í”„
main() {
    while true; do
        show_menu
        read -r choice
        
        case $choice in
            1) deploy_infrastructure ;;
            2) initialize_server ;;
            3) setup_block_storage ;;
            4) setup_backups ;;
            5) setup_monitoring ;;
            6) check_status ;;
            7) disaster_recovery ;;
            8) full_setup ;;
            0) echo "ì¢…ë£Œí•©ë‹ˆë‹¤."; exit 0 ;;
            *) echo -e "${RED}ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.${NC}" ;;
        esac
        
        echo -e "\n${YELLOW}Enterë¥¼ ëˆŒëŸ¬ ê³„ì†...${NC}"
        read
        clear
    done
}

# ì‹¤í–‰
main
```

### Makefile ìë™í™”
```makefile
# Makefile
.PHONY: help init plan apply destroy status backup monitor

# ë³€ìˆ˜
TERRAFORM_DIR = ./infrastructure
SERVER_IP = $(shell cd $(TERRAFORM_DIR) && terraform output -raw instance_ip 2>/dev/null)

help: ## ë„ì›€ë§ í‘œì‹œ
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | \
		awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-15s\033[0m %s\n", $$1, $$2}'

init: ## Terraform ì´ˆê¸°í™”
	cd $(TERRAFORM_DIR) && terraform init

plan: ## ë°°í¬ ê³„íš í™•ì¸
	cd $(TERRAFORM_DIR) && terraform plan

apply: ## ì¸í”„ë¼ ë°°í¬
	cd $(TERRAFORM_DIR) && terraform apply

destroy: ## ì¸í”„ë¼ ì‚­ì œ
	cd $(TERRAFORM_DIR) && terraform destroy

status: ## ì„œë²„ ìƒíƒœ í™•ì¸
	@echo "=== ì„œë²„ ìƒíƒœ ==="
	@vultr-cli instance list
	@echo "\n=== Block Storage ==="
	@vultr-cli block-storage list
	@echo "\n=== ìŠ¤ëƒ…ìƒ· ==="
	@vultr-cli snapshot list | head -5

backup: ## ì¦‰ì‹œ ë°±ì—… ì‹¤í–‰
	ssh root@$(SERVER_IP) "/usr/local/bin/auto-backup.sh"
	@echo "âœ… ë°±ì—… ì™„ë£Œ"

monitor: ## ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
	@echo "Netdata: http://$(SERVER_IP):19999"
	@echo "Uptime Kuma: http://$(SERVER_IP):3001"
	@echo "Coolify: https://$(SERVER_IP):8000"

ssh: ## ì„œë²„ SSH ì ‘ì†
	ssh root@$(SERVER_IP)

logs: ## ì„œë²„ ë¡œê·¸ í™•ì¸
	ssh root@$(SERVER_IP) "journalctl -f"

docker-ps: ## Docker ì»¨í…Œì´ë„ˆ ìƒíƒœ
	ssh root@$(SERVER_IP) "docker ps"

snapshot: ## ìŠ¤ëƒ…ìƒ· ìƒì„±
	vultr-cli snapshot create \
		--instance-id $(shell cd $(TERRAFORM_DIR) && terraform output -raw instance_id) \
		--description "manual-$(shell date +%Y%m%d-%H%M%S)"

storage-add: ## Block Storage ì¶”ê°€
	cd $(TERRAFORM_DIR) && \
	terraform apply -target=vultr_block_storage.backup

import-existing: ## ê¸°ì¡´ ì¸í”„ë¼ ê°€ì ¸ì˜¤ê¸°
	@echo "Instance IDë¥¼ ì…ë ¥í•˜ì„¸ìš”:"
	@read INSTANCE_ID && \
	cd $(TERRAFORM_DIR) && \
	terraform import vultr_instance.main $$INSTANCE_ID

validate: ## Terraform êµ¬ì„± ê²€ì¦
	cd $(TERRAFORM_DIR) && terraform validate

fmt: ## Terraform ì½”ë“œ í¬ë§·íŒ…
	cd $(TERRAFORM_DIR) && terraform fmt -recursive

cost: ## ì˜ˆìƒ ë¹„ìš© ê³„ì‚°
	@echo "=== ì›”ë³„ ì˜ˆìƒ ë¹„ìš© ==="
	@echo "ì¸ìŠ¤í„´ìŠ¤ (2vCPU, 16GB): \$$80"
	@echo "Block Storage (100GB): \$$10"
	@echo "ìŠ¤ëƒ…ìƒ· (5ê°œ í‰ê· ): \$$5"
	@echo "ì´ê³„: \$$95/ì›”"
```

---

## 5. CI/CD í†µí•©

### GitHub Actions
```yaml
# .github/workflows/infrastructure.yml
name: Infrastructure Management

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
          - backup

env:
  VULTR_API_KEY: ${{ secrets.VULTR_API_KEY }}

jobs:
  terraform:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0
    
    - name: Terraform Init
      run: |
        cd infrastructure
        terraform init
    
    - name: Terraform Plan
      if: github.event.inputs.action == 'plan'
      run: |
        cd infrastructure
        terraform plan
    
    - name: Terraform Apply
      if: github.event.inputs.action == 'apply'
      run: |
        cd infrastructure
        terraform apply -auto-approve
    
    - name: Create Backup
      if: github.event.inputs.action == 'backup'
      run: |
        curl -L https://github.com/vultr/vultr-cli/releases/latest/download/vultr-cli_Linux_x86_64.tar.gz | tar xz
        ./vultr-cli snapshot create \
          --instance-id $(cd infrastructure && terraform output -raw instance_id) \
          --description "github-action-$(date +%Y%m%d)"
```

### GitLab CI/CD
```yaml
# .gitlab-ci.yml
stages:
  - validate
  - plan
  - apply

variables:
  TF_ROOT: ${CI_PROJECT_DIR}/infrastructure

before_script:
  - apk add --no-cache terraform
  - cd ${TF_ROOT}
  - terraform init

validate:
  stage: validate
  script:
    - terraform validate
    - terraform fmt -check

plan:
  stage: plan
  script:
    - terraform plan -out=tfplan
  artifacts:
    paths:
      - ${TF_ROOT}/tfplan
    expire_in: 7 days

apply:
  stage: apply
  script:
    - terraform apply tfplan
  when: manual
  only:
    - main
```

---

## ğŸ“Œ Quick Start

### 1ë¶„ ì„¤ì •
```bash
# 1. API í‚¤ ì„¤ì •
export VULTR_API_KEY="your-api-key"

# 2. Vultr CLI ì„¤ì¹˜
curl -L https://github.com/vultr/vultr-cli/releases/latest/download/vultr-cli_Linux_x86_64.tar.gz | tar xz
sudo mv vultr-cli /usr/local/bin/

# 3. ì„œë²„ í™•ì¸
vultr-cli instance list

# 4. Block Storage ì¶”ê°€
vultr-cli block-storage create --region sgp --size 100 --label backup
```

### Terraform ë¹ ë¥¸ ì‹œì‘
```bash
# 1. í”„ë¡œì íŠ¸ í´ë¡ 
git clone <your-repo>
cd infrastructure

# 2. API í‚¤ ì„¤ì •
echo 'vultr_api_key = "your-key"' > terraform.tfvars

# 3. ë°°í¬
terraform init
terraform apply

# 4. ì ‘ì† ì •ë³´
terraform output ssh_command
```

---

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **API í‚¤ ê´€ë¦¬**
   - ì ˆëŒ€ ì½”ë“œì— í•˜ë“œì½”ë”©í•˜ì§€ ì•Šê¸°
   - í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ì‹œí¬ë¦¿ ë§¤ë‹ˆì € ì‚¬ìš©
   - ì •ê¸°ì ìœ¼ë¡œ í‚¤ êµì²´

2. **ì ‘ê·¼ ì œì–´**
   - IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì„¤ì •
   - SSH í‚¤ ì¸ì¦ë§Œ ì‚¬ìš©
   - ë°©í™”ë²½ ê·œì¹™ ìµœì†Œí™”

3. **ë°±ì—… ì•”í˜¸í™”**
   - ë°±ì—… íŒŒì¼ ì•”í˜¸í™”
   - ì „ì†¡ ì¤‘ SSL/TLS ì‚¬ìš©
   - ì ‘ê·¼ ë¡œê·¸ ëª¨ë‹ˆí„°ë§

4. **ëª¨ë‹ˆí„°ë§**
   - ë¹„ì •ìƒ ì ‘ê·¼ ì•Œë¦¼
   - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì 
   - ë³´ì•ˆ ì´ë²¤íŠ¸ ë¡œê¹…

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Vultr API ë¬¸ì„œ](https://www.vultr.com/api/)
- [Vultr CLI GitHub](https://github.com/vultr/vultr-cli)
- [Terraform Vultr Provider](https://registry.terraform.io/providers/vultr/vultr/latest/docs)
- [Coolify ë¬¸ì„œ](https://coolify.io/docs)

---

## ğŸ’¡ ë¬¸ì œ í•´ê²°

### API í‚¤ ì˜¤ë¥˜
```bash
# API í‚¤ í™•ì¸
echo $VULTR_API_KEY

# ê¶Œí•œ í™•ì¸
vultr-cli account
```

### Terraform ìƒíƒœ ë™ê¸°í™”
```bash
# ìƒíƒœ ìƒˆë¡œê³ ì¹¨
terraform refresh

# ìƒíƒœ ì¬êµ¬ì„±
terraform init -reconfigure
```

### Block Storage ë§ˆìš´íŠ¸ ì‹¤íŒ¨
```bash
# ë””ë°”ì´ìŠ¤ í™•ì¸
lsblk

# ìˆ˜ë™ ë§ˆìš´íŠ¸
mount /dev/vdb /mnt/blockstorage

# fstab í™•ì¸
cat /etc/fstab
```

---

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2024ë…„ 1ì›”*